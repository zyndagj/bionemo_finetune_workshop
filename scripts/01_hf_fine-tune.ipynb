{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6441711c-a040-4895-8500-b2af0cc6909c",
   "metadata": {},
   "source": [
    "# Fine-tuning ESM-2\n",
    "\n",
    "In this notebook, we'll be fine-tuning ESM-2 to predict the subcelluar location of proteins based on the input amino acid sequence. We'll start by showing how this can be done with the published model [hosted on HuggingFace](https://huggingface.co/facebook/esm2_t33_650M_UR50D) and then showing how this can be done using NVIDIA's [BioNeMo 2 Framework](https://docs.nvidia.com/bionemo-framework/latest/user-guide/)\n",
    "\n",
    "> Inspired by ESM-2's [example notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb) for fine-tuning.\n",
    "\n",
    "This notebook needs the [evaluate](https://pypi.org/project/evaluate/) package, but it's not present in the BioNeMo v2.3 container, so we'll need to manually install it with `pip`\n",
    "\n",
    "> Make sure to restart the kernel of this notebook after installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7183b2-be3f-4fa9-b227-909c2d63aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/igraph-0.11.8-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.11.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/texttable-1.7.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.13a0+0d33366-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: evaluate in /home/gzynda/.local/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg (from evaluate) (0.3.9)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.27.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.11.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Installing collected packages: dill\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lightning-thunder 0.2.0.dev0 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dill-0.3.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "# Restart kernel after installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import requests, pandas, os, evaluate\n",
    "# Rerun previous cell and restart kernel if this fails\n",
    "from io import BytesIO\n",
    "\n",
    "# Set environment variables for huggingface\n",
    "for var in ['HF_HOME','HF_HUB_CACHE']:\n",
    "    os.environ[var] = '/tmp/hf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee575bec",
   "metadata": {},
   "source": [
    "We're going to fine-tune ESM2-650M using human protein sequences (`organism_id:9606`) that we reviewed (`reviewed:true`), and range from 80 to 500 amino acids in length (`length:[80 TO 500]`) and only outputting the `Sequence` and `Subcellular location [CC]` columns. [UniProt](https://www.uniprot.org/) actually has a REST API, so this query has been encoded into `query_url`.\n",
    "\n",
    "This download can sometimes fail or take a while, so we cache the data in parquet format once it succeeds. This will make any repeated runs of the notebook go much faster on the same compute node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5549b6-acee-4c42-82b7-0560ff59b19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Subcellular location [CC]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A0K2S4Q6</td>\n",
       "      <td>MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...</td>\n",
       "      <td>SUBCELLULAR LOCATION: [Isoform 1]: Membrane {E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0AVI4</td>\n",
       "      <td>MDSPEVTFTLAYLVFAVCFVFTPNEFHAAGLTVQNLLSGWLGSEDA...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Endoplasmic reticulum me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0JLT2</td>\n",
       "      <td>MENFTALFGAQADPPPPPTALGFGPGKPPPPPPPPAGGGPGTAPPP...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000305}.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Secreted {ECO:0000303|Pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0PJY2</td>\n",
       "      <td>MDSSCHNATTKMLATAPARGNMMSTSKPLAFSIERIMARTPEPKAL...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000269|Pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11972</th>\n",
       "      <td>Q9H8W2</td>\n",
       "      <td>MRPGSSPRAPECGAPALPRPQLDRLPARPAPSRGRGAPSLRWPAKE...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11973</th>\n",
       "      <td>Q9HAA7</td>\n",
       "      <td>MLFGIRILVNTPSPLVTGLHHYNPSIHRDQGECANQWRKGPGSAHL...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974</th>\n",
       "      <td>Q9NZ38</td>\n",
       "      <td>MAFPGQSDTKMQWPEVPALPLLSSLCMAMVRKSSALGKEVGRRSEG...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>Q9UFV3</td>\n",
       "      <td>MAETYRRSRQHEQLPGQRHMDLLTGYSKLIQSRLKLLLHLGSQPPV...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>Q9Y6C7</td>\n",
       "      <td>MAHHSLNTFYIWHNNVLHTHLVFFLPHLLNQPFSRGSFLIWLLLCW...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11977 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Entry                                           Sequence  \\\n",
       "0      A0A0K2S4Q6  MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...   \n",
       "1          A0AVI4  MDSPEVTFTLAYLVFAVCFVFTPNEFHAAGLTVQNLLSGWLGSEDA...   \n",
       "2          A0JLT2  MENFTALFGAQADPPPPPTALGFGPGKPPPPPPPPAGGGPGTAPPP...   \n",
       "3          A0M8Q6  GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...   \n",
       "4          A0PJY2  MDSSCHNATTKMLATAPARGNMMSTSKPLAFSIERIMARTPEPKAL...   \n",
       "...           ...                                                ...   \n",
       "11972      Q9H8W2  MRPGSSPRAPECGAPALPRPQLDRLPARPAPSRGRGAPSLRWPAKE...   \n",
       "11973      Q9HAA7  MLFGIRILVNTPSPLVTGLHHYNPSIHRDQGECANQWRKGPGSAHL...   \n",
       "11974      Q9NZ38  MAFPGQSDTKMQWPEVPALPLLSSLCMAMVRKSSALGKEVGRRSEG...   \n",
       "11975      Q9UFV3  MAETYRRSRQHEQLPGQRHMDLLTGYSKLIQSRLKLLLHLGSQPPV...   \n",
       "11976      Q9Y6C7  MAHHSLNTFYIWHNNVLHTHLVFFLPHLLNQPFSRGSFLIWLLLCW...   \n",
       "\n",
       "                               Subcellular location [CC]  \n",
       "0      SUBCELLULAR LOCATION: [Isoform 1]: Membrane {E...  \n",
       "1      SUBCELLULAR LOCATION: Endoplasmic reticulum me...  \n",
       "2           SUBCELLULAR LOCATION: Nucleus {ECO:0000305}.  \n",
       "3      SUBCELLULAR LOCATION: Secreted {ECO:0000303|Pu...  \n",
       "4      SUBCELLULAR LOCATION: Nucleus {ECO:0000269|Pub...  \n",
       "...                                                  ...  \n",
       "11972                                               None  \n",
       "11973                                               None  \n",
       "11974                                               None  \n",
       "11975                                               None  \n",
       "11976                                               None  \n",
       "\n",
       "[11977 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_url = \"https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Csequence%2Ccc_subcellular_location&format=tsv&query=%28%28organism_id%3A9606%29%20AND%20%28reviewed%3Atrue%29%20AND%20%28length%3A%5B80%20TO%20500%5D%29%29\"\n",
    "tmp_file = \"/tmp/uniprot.parquet.gz\"\n",
    "\n",
    "# Logic to quickly load data if cached\n",
    "if not os.path.exists(tmp_file):\n",
    "    # Download data\n",
    "    uniprot_request = requests.get(query_url)\n",
    "    # Store data as binary object that works like a file\n",
    "    bio = BytesIO(uniprot_request.content)\n",
    "    # Read binary object as compressed csv\n",
    "    df = pandas.read_csv(bio, compression='gzip', sep='\\t')\n",
    "    # Cache to local location for faster reloads\n",
    "    df.to_parquet(tmp_file, compression=\"gzip\")\n",
    "else:\n",
    "    # Load from cache\n",
    "    df = pandas.read_parquet(tmp_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d0f04",
   "metadata": {},
   "source": [
    "Our goal is to train a model that can predict proteins that are located in the [cytosol](https://en.wikipedia.org/wiki/Cytosol) (intracellular fluid) or the membrane of a cell. Proteins in the cytosol have a `Subcellular location [CC]` of `Cytoplasm` or `Cytosol`. Proteins in the cell membrane have a `Subcellular location [CC]` of `Membrane` or `Cell membrane`.\n",
    "\n",
    "Once these are selected, we can create new dataframes for each type, while also excluding proteins that exist in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4ae7c9-4161-40c9-850d-6d5036f022fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Subcellular location [CC]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A1E959</td>\n",
       "      <td>MKIIILLGFLGATLSAPLIPQRLMSASNSNELLLNLNNGQLLPLQL...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Secreted {ECO:0000250|Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A1XBS5</td>\n",
       "      <td>MMRRTLENRNAQTKQLQTAVSNVEKHFGELCQIFAAYVRKTARLRD...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A2RU49</td>\n",
       "      <td>MSSGNYQQSEALSKPTFSEEQASALVESVFGLKVSKVRPLPSYDDQ...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cytoplasm {ECO:0000305}.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A2RUH7</td>\n",
       "      <td>MEAATAPEVAAGSKLKVKEASPADAEPPQASPGQGAGSPTPQLLPP...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cytoplasm, myofibril, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A4D126</td>\n",
       "      <td>MEAGPPGSARPAEPGPCLSGQRGADHTASASLQSVAGTEPGRHPQA...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cytoplasm, cytosol {ECO:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>Q8NBC4</td>\n",
       "      <td>MFPRPVLNSRAQAILLPQPPNMLDHRQWPPRLASFPFTKTGMLSRA...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11535</th>\n",
       "      <td>Q8TDY3</td>\n",
       "      <td>MFNPHALDSPAVIFDNGSGFCKAGLSGEFGPRHMVSSIVGHLKFQA...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cytoplasm, cytoskeleton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>Q8WWF8</td>\n",
       "      <td>MAGTARHDREMAIQAKKKLTTATDPIERLRLQCLARGSAGIKGLGR...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cytoplasm {ECO:0000305}.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11671</th>\n",
       "      <td>Q9NUJ7</td>\n",
       "      <td>MGGQVSASNSFSRLHCRNANEDWMSALCPRLWDVPLHHLSIPGSHD...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11679</th>\n",
       "      <td>Q9P2W6</td>\n",
       "      <td>MGRTWCGMWRRRRPGRRSAVPRWPHLSSQSGVEPPDRWTGTPGWPS...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cytoplasm.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2644 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entry                                           Sequence  \\\n",
       "9      A1E959  MKIIILLGFLGATLSAPLIPQRLMSASNSNELLLNLNNGQLLPLQL...   \n",
       "14     A1XBS5  MMRRTLENRNAQTKQLQTAVSNVEKHFGELCQIFAAYVRKTARLRD...   \n",
       "18     A2RU49  MSSGNYQQSEALSKPTFSEEQASALVESVFGLKVSKVRPLPSYDDQ...   \n",
       "20     A2RUH7  MEAATAPEVAAGSKLKVKEASPADAEPPQASPGQGAGSPTPQLLPP...   \n",
       "21     A4D126  MEAGPPGSARPAEPGPCLSGQRGADHTASASLQSVAGTEPGRHPQA...   \n",
       "...       ...                                                ...   \n",
       "11495  Q8NBC4  MFPRPVLNSRAQAILLPQPPNMLDHRQWPPRLASFPFTKTGMLSRA...   \n",
       "11535  Q8TDY3  MFNPHALDSPAVIFDNGSGFCKAGLSGEFGPRHMVSSIVGHLKFQA...   \n",
       "11547  Q8WWF8  MAGTARHDREMAIQAKKKLTTATDPIERLRLQCLARGSAGIKGLGR...   \n",
       "11671  Q9NUJ7  MGGQVSASNSFSRLHCRNANEDWMSALCPRLWDVPLHHLSIPGSHD...   \n",
       "11679  Q9P2W6  MGRTWCGMWRRRRPGRRSAVPRWPHLSSQSGVEPPDRWTGTPGWPS...   \n",
       "\n",
       "                               Subcellular location [CC]  \n",
       "9      SUBCELLULAR LOCATION: Secreted {ECO:0000250|Un...  \n",
       "14     SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...  \n",
       "18        SUBCELLULAR LOCATION: Cytoplasm {ECO:0000305}.  \n",
       "20     SUBCELLULAR LOCATION: Cytoplasm, myofibril, sa...  \n",
       "21     SUBCELLULAR LOCATION: Cytoplasm, cytosol {ECO:...  \n",
       "...                                                  ...  \n",
       "11495  SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...  \n",
       "11535  SUBCELLULAR LOCATION: Cytoplasm, cytoskeleton ...  \n",
       "11547     SUBCELLULAR LOCATION: Cytoplasm {ECO:0000305}.  \n",
       "11671  SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...  \n",
       "11679                   SUBCELLULAR LOCATION: Cytoplasm.  \n",
       "\n",
       "[2644 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop proteins with missing columns\n",
    "df = df.dropna()\n",
    "# Get ids of proteins with Cytosol or Cytoplasm locations\n",
    "cytosolic = df['Subcellular location [CC]'].str.contains(\"Cytosol\") | df['Subcellular location [CC]'].str.contains(\"Cytoplasm\")\n",
    "# Get ids of proteins with Membrane or Cell membrane locations\n",
    "membrane = df['Subcellular location [CC]'].str.contains(\"Membrane\") | df['Subcellular location [CC]'].str.contains(\"Cell membrane\")\n",
    "\n",
    "# Create new cytosolic dataframe with proteins\n",
    "cytosolic_df = df[cytosolic & ~membrane]\n",
    "cytosolic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7079889f-4942-420b-82cc-392b3de0f420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Subcellular location [CC]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A0K2S4Q6</td>\n",
       "      <td>MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...</td>\n",
       "      <td>SUBCELLULAR LOCATION: [Isoform 1]: Membrane {E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Secreted {ECO:0000303|Pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A2RU14</td>\n",
       "      <td>MAGTVLGVGAGVFILALLWVAVLLLCVLLSRASGAARFSVIFLFFG...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A5X5Y0</td>\n",
       "      <td>MEGSWFHRKRFSFYLLLGFLLQGRGVTFTINCSGFGQHGADPTALN...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Postsynaptic cell membra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>A6ND01</td>\n",
       "      <td>MACWWPLLLELWTVMPTWAGDELLNICMNAKHHKRVPSPEDKLYEE...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895</th>\n",
       "      <td>Q86UQ5</td>\n",
       "      <td>MQSDIYHPGHSFPSWVLCWVHSCGHEGHLRETAEIRKTHQNGDLQI...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11918</th>\n",
       "      <td>Q8N8V8</td>\n",
       "      <td>MLLKVRRASLKPPATPHQGAFRAGNVIGQLIYLLTWSLFTAWLRPP...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11955</th>\n",
       "      <td>Q96N68</td>\n",
       "      <td>MQGQGALKESHIHLPTEQPEASLVLQGQLAESSALGPKGALRPQAQ...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11963</th>\n",
       "      <td>Q9H0A3</td>\n",
       "      <td>MMNNTDFLMLNNPWNKLCLVSMDFCFPLDFVSNLFWIFASKFIIVT...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11966</th>\n",
       "      <td>Q9H354</td>\n",
       "      <td>MNKHNLRLVQLASELILIEIIPKLFLSQVTTISHIKREKIPPNHRK...</td>\n",
       "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2538 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Entry                                           Sequence  \\\n",
       "0      A0A0K2S4Q6  MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...   \n",
       "3          A0M8Q6  GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...   \n",
       "17         A2RU14  MAGTVLGVGAGVFILALLWVAVLLLCVLLSRASGAARFSVIFLFFG...   \n",
       "33         A5X5Y0  MEGSWFHRKRFSFYLLLGFLLQGRGVTFTINCSGFGQHGADPTALN...   \n",
       "36         A6ND01  MACWWPLLLELWTVMPTWAGDELLNICMNAKHHKRVPSPEDKLYEE...   \n",
       "...           ...                                                ...   \n",
       "11895      Q86UQ5  MQSDIYHPGHSFPSWVLCWVHSCGHEGHLRETAEIRKTHQNGDLQI...   \n",
       "11918      Q8N8V8  MLLKVRRASLKPPATPHQGAFRAGNVIGQLIYLLTWSLFTAWLRPP...   \n",
       "11955      Q96N68  MQGQGALKESHIHLPTEQPEASLVLQGQLAESSALGPKGALRPQAQ...   \n",
       "11963      Q9H0A3  MMNNTDFLMLNNPWNKLCLVSMDFCFPLDFVSNLFWIFASKFIIVT...   \n",
       "11966      Q9H354  MNKHNLRLVQLASELILIEIIPKLFLSQVTTISHIKREKIPPNHRK...   \n",
       "\n",
       "                               Subcellular location [CC]  \n",
       "0      SUBCELLULAR LOCATION: [Isoform 1]: Membrane {E...  \n",
       "3      SUBCELLULAR LOCATION: Secreted {ECO:0000303|Pu...  \n",
       "17     SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
       "33     SUBCELLULAR LOCATION: Postsynaptic cell membra...  \n",
       "36     SUBCELLULAR LOCATION: Cell membrane {ECO:00002...  \n",
       "...                                                  ...  \n",
       "11895  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
       "11918  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
       "11955  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
       "11963  SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...  \n",
       "11966  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
       "\n",
       "[2538 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new membrane dataframe with proteins\n",
    "membrane_df = df[membrane & ~cytosolic]\n",
    "membrane_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1677d52",
   "metadata": {},
   "source": [
    "Now that we've filtered and separated out he proteins of interest, we can extract the sequences, and encode the locations as `0` for cytosolic proteins and `1` for membrane proteins. Then, we can combine the types together into two lists: sequences and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00518a4-9750-47cf-aac6-f8789028a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cytosolic_sequences = cytosolic_df[\"Sequence\"].tolist()\n",
    "cytosolic_labels = [0 for protein in cytosolic_sequences]\n",
    "membrane_sequences = membrane_df[\"Sequence\"].tolist()\n",
    "membrane_labels = [1 for protein in membrane_sequences]\n",
    "\n",
    "sequences = cytosolic_sequences + membrane_sequences\n",
    "labels = cytosolic_labels + membrane_labels\n",
    "\n",
    "# Quick check to make sure we got it right\n",
    "assert(len(sequences) == len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ff606e",
   "metadata": {},
   "source": [
    "When training a model, you need training data for the model to learn from and validation data that the model never learns from to make sure what it learns is generally applicable. We're going to use sklearn to split our lists 75% and 25% into `train` and `test` datasets. Once that is done, we'll cache the datasets to CSV (comma separate values) format so both fine-tuning methods use the same data.\n",
    "\n",
    "BioNeMo also only validates for two steps while training, so we're going to truncate our test data to 64 items (8 batches of 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9bdc9c-50eb-402b-97a5-3f4a7af4a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)\n",
    "\n",
    "pandas.DataFrame({\"sequences\":train_sequences, \"labels\":train_labels}).to_csv(\"/tmp/train_df.csv\")\n",
    "pandas.DataFrame({\"sequences\":test_sequences, \"labels\":test_labels}).to_csv(\"/tmp/test_df.csv\")\n",
    "\n",
    "# Only keep the first 16 validation sequences for parity with BioNeMo\n",
    "test_sequences_small = test_sequences[:64]\n",
    "test_labels_small = test_labels[:64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f18291",
   "metadata": {},
   "source": [
    "Inputs sequences need to be tokenized into numerical format for the model. When we pull down the ESM2-650M model checkpoint from HuggingFace, we get the tokenizer too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ae2a58-6801-4228-8536-b1b35440cdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Using the ESM2 650M model checkpoint from HuggingFace\n",
    "model_checkpoint = \"facebook/esm2_t33_650M_UR50D\"\n",
    "\n",
    "# Load the tokenizer from the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff79cf6",
   "metadata": {},
   "source": [
    "To understand what happens during tokenization, we can tokenize the first sequence.\n",
    "\n",
    "You'll notice that the tokenized sequence is 2 values longer than the original sequence. That's because there are tokens to represent the START and END of the sequence for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df582064-246f-4343-a1a6-b77dedb0304d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 20, 7, 5, 11, 23, 4, 16, 7, 7, 6, 18, 7, 11, 8, 18, 7, 6, 22, 12, 6, 7, 12, 7, 11, 11, 8, 11, 17, 13, 22, 7, 7, 11, 23, 6, 19, 11, 12, 14, 11, 23, 10, 15, 4, 13, 9, 4, 6, 8, 15, 6, 4, 22, 5, 13, 23, 7, 20, 5, 11, 6, 4, 19, 21, 23, 15, 14, 4, 7, 13, 12, 4, 12, 4, 14, 6, 19, 7, 16, 5, 23, 10, 5, 4, 20, 12, 5, 5, 8, 7, 4, 6, 4, 14, 5, 12, 4, 4, 4, 4, 11, 7, 4, 14, 23, 12, 10, 20, 6, 16, 9, 14, 6, 7, 5, 15, 19, 10, 10, 5, 16, 4, 5, 6, 7, 4, 4, 12, 4, 4, 5, 4, 23, 5, 4, 7, 5, 11, 12, 22, 18, 14, 7, 23, 5, 21, 10, 9, 11, 11, 12, 7, 8, 18, 6, 19, 8, 4, 19, 5, 6, 22, 12, 6, 5, 7, 4, 23, 4, 7, 6, 6, 23, 7, 12, 4, 23, 23, 5, 6, 13, 5, 16, 5, 18, 6, 9, 17, 10, 18, 19, 19, 11, 5, 6, 8, 8, 8, 14, 11, 21, 5, 15, 8, 5, 21, 7, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the first sequence for demonstration\n",
    "seq = train_sequence[0]\n",
    "tokenized = tokenizer(seq)\n",
    "\n",
    "print(f\"Sequence length: {len(seq)}\\nToken length: {len(tokenized['input_ids'])}\")\n",
    "\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2475b80-405a-4e88-927b-b0c79131fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all sequences\n",
    "train_tokenized = tokenizer(train_sequences)\n",
    "test_tokenized = tokenizer(test_sequences_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a4e9b",
   "metadata": {},
   "source": [
    "After tokenizing all of our sequences, we can create a `Dataset` object that will handle data shuffling and iterating while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "348deb2a-6cce-4e46-a537-4801974ee75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3886, 3) ['input_ids', 'attention_mask', 'labels']\n",
      "(16, 3) ['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/usr/local/lib/python3.12/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "\n",
    "# Add labels to Dataset\n",
    "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels_small)\n",
    "\n",
    "# Print the shape and columns of the datasets after adding labels\n",
    "print(train_dataset.shape, list(train_dataset[0].keys()))\n",
    "print(test_dataset.shape, list(test_dataset[0].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7695ad",
   "metadata": {},
   "source": [
    "Now that data preparation is done, we can pull the model and configure it. We're going to be training the model to classify an input sequence as one of two labels {0: cytosolic, 1: membrane}, so we're going to load the ESM-2 650M checkpoint using the `AutoModelForSequenceClassification` class. Notice that we're also telling it that there are two possible labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0f92ae8-e17b-444f-83d7-b8921e0c8708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = max(train_labels + test_labels) + 1  # 2: {0: cytosolic, 1: membrane}\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df3d84",
   "metadata": {},
   "source": [
    "After loading the model, we can configure the training run. To mimic the way BioNeMo does fine-tuning, we're going to train for 200 steps and evaluate every 50 steps. On a 48GB GPU like the L40S, a batch size of 8 can be used. For other GPUs, experiment with other values based on memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff0dcbf-12b8-48b3-b900-dd6d4dece154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size = 8 # Works for 48GB GPU\n",
    "strat = \"steps\" # \"epoch\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"/tmp/{model_name}-finetuned-localization\", # Make sure to change this for a real model\n",
    "    eval_strategy = strat,\n",
    "    save_strategy = strat,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    max_steps=200,\n",
    "    eval_steps=50,\n",
    "    #num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    include_tokens_per_second=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa491977",
   "metadata": {},
   "source": [
    "We're also going to use HuggingFace's evaluate package to compute the accuracy of the classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820334ca-af52-43c1-8b07-a1b3ee5c0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2226002a",
   "metadata": {},
   "source": [
    "Up next, we create the `Trainer` class using the model, data, and configurations. If everything is valid, we can start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b65d8f-0930-443f-9947-99a00eb83ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_424/2227356937.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e795d1c-86d7-4968-b4d5-d58ff4739c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 01:50, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.177743</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.032178</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.018176</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.020032</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the best model at /tmp/esm2_t33_650M_UR50D-finetuned-localization/checkpoint-100/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.2943057441711426, metrics={'train_runtime': 111.3586, 'train_samples_per_second': 14.368, 'train_steps_per_second': 1.796, 'train_tokens_per_second': 6867.903, 'total_flos': 2792200504173504.0, 'train_loss': 0.2943057441711426, 'epoch': 0.411522633744856})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dac9f0-8b55-45e4-93a6-bff8283dd292",
   "metadata": {},
   "source": [
    "Once training is done, stop this notebook so the model is freed from memory and we can do fine-tuning with BioNeMo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b19e77",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
