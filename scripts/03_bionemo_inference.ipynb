{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4373abfb-e7d3-4560-8d28-dd19793bdb58",
   "metadata": {},
   "source": [
    "# BioNeMo Fine-Tuning & Inference\n",
    "\n",
    "> Inspired by\n",
    "> - [BioNeMo2 Inference Notebook](https://github.com/NVIDIA/bionemo-framework/blob/v2.3/docs/docs/user-guide/examples/bionemo-esm2/inference.ipynb)\n",
    "> - [BioNeMo2 Inference Example](https://docs.nvidia.com/bionemo-framework/latest/user-guide/examples/bionemo-esm2/inference/)\n",
    "\n",
    "Before running fine-tuning, take a look at `02_bionemo_fine-tune.py` to see how fine-tuning runs are set up in BioNeMo. Some interesting sections to look at are:\n",
    "\n",
    "- nl.MegatronStrategy - How model parallelism is configured\n",
    "- biobert_lightning_module - Using PEFT for training\n",
    "- ESM2FineTuneSeqConfig - Config for sequence classification\n",
    "- nl.Trainer - Set the number of GPUs and nodes\n",
    "\n",
    "After going through the code, run it with the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e18737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fine-tuning\n",
    "! python 02_bionemo_fine-tune.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495657da",
   "metadata": {},
   "source": [
    "At the end of the run, you should see a `Experiment completed with checkpoint stored at` message pointing to final checkpoint. Update `checkpoint_path` with the name of your model. Feel free to update `work_dir` if `/tmp` is limited. `valid_csv` should also have already been created in `01_hf_fine-tune.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5549b6-acee-4c42-82b7-0560ff59b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this checkpoint after fine-tuning\n",
    "checkpoint_path = \"/tmp/tmpxs8k_u4j/finetune_regressor/checkpoints/finetune_regressor--reduced_train_loss=0.0302-epoch=0-consumed_samples=1600.0-last\"\n",
    "\n",
    "# This gets created after running 01_hf_fine-tune.ipynb\n",
    "valid_csv = \"/tmp/test_df.csv\"\n",
    "work_dir = \"/tmp/work\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60332749-0aea-4579-8199-d664fc810f66",
   "metadata": {},
   "source": [
    "After fine-tuning a model, it's good to see how well it performs. This can be done by running inference on all the test data we previously cached in `/tmp/test_df.csv`.\n",
    "\n",
    "Similar to fine-tuning, BioNeMo inference mush be run in a separate process, which is easy to do through calling a shell with `!` in Jupyter.\n",
    "\n",
    "| Argument | Description |\n",
    "|:========:|:============|\n",
    "| checkpoint-path | path to model checkpoint |\n",
    "| data-path | CSV with \"sequences\" and \"labels\" columns |\n",
    "| results-path | Where output `.pt` will be written |\n",
    "| micro-batch-size | Number of inputs in each GPU batch |\n",
    "| num-gpus | Number of GPUs to use for inference |\n",
    "| precision | Model precision to use |\n",
    "| config-class | ESM2FineTuneSeqConfig tells BioNeMo that we did sequence classification |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505b100-0f49-442e-a2f3-78718f2c47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! infer_esm2 --checkpoint-path {checkpoint_path} \\\n",
    "             --data-path {valid_csv} \\\n",
    "             --results-path {work_dir} \\\n",
    "             --micro-batch-size 3 \\\n",
    "             --num-gpus 1 \\\n",
    "             --precision \"bf16-mixed\" \\\n",
    "             --include-hiddens \\\n",
    "             --include-embeddings \\\n",
    "             --include-logits \\\n",
    "             --include-input-ids \\\n",
    "             --config-class ESM2FineTuneSeqConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fade6e",
   "metadata": {},
   "source": [
    "Since BioNeMo is run from a separate process, output is written to a `.pt` file. This can be loaded using `torch.load` and the contents can be examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227bdb2-17ac-43f5-a9df-f40b46ebdcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "results = torch.load(f\"{work_dir}/predictions__rank_0.pt\")\n",
    "\n",
    "# Print out the contents of inference results\n",
    "for key, val in results.items():\n",
    "    if val is not None:\n",
    "        print(f'{key}\\t{val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed8e9a",
   "metadata": {},
   "source": [
    "The `regression_output` key contains all the classifications. To understand how well the model did at fine-tuning, we can append it to the test dataframe after rounding the classification to 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5ac0e-6951-41a3-ba24-10378bd300b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# Print out the original sequence, true label, and inferred label\n",
    "test_df = pandas.read_csv(\"/tmp/test_df.csv\")[['sequences','labels']]\n",
    "test_df['inference'] = results['regression_output'].round().int().numpy()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de617817",
   "metadata": {},
   "source": [
    "Accuracy or other metrics and then be computed from these results. How did your model do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe64909-74a4-4519-a4db-e764043843a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy from whole dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_df['labels'], test_df['inference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846e98c-ff27-4242-a2f5-61dc158e431a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
